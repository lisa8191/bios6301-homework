---
title: "Assignment 1"
author: Ya-Chen Lin
output: pdf_document
---
Create a Data Set
```{r}
gender <- c('M','M','F','M','F','F','M','F','M')
age <- c(34, 64, 38, 63, 40, 73, 27, 51, 47)
smoker <- c('no','yes','no','no','yes','no','no','no','yes')
exercise <- factor(c('moderate','frequent','some','some','moderate','none','none','moderate','moderate'),
                   levels=c('none','some','moderate','frequent'), ordered=TRUE
)
los <- c(4,8,1,10,6,3,9,4,8)
x <- data.frame(gender, age, smoker, exercise, los)
x

```

# Question 1:  
Looking at the output, which coefficient seems to have the highest effect on los? 
```{r}
lm(los ~ gender + age + smoker + exercise, dat=x)
```
Based on the coeffecient, genderM seems to have the highest effect on los since the coeffecient value is the highest.
<br><br>
Q1.Create a model using [los] and [gender] and assign it to the variable mod. Run the summary function with mod as its argument.

```{r}
mod <- lm (los ~ gender, dat = x)
summary (mod)
```

    
# Question 1:      
What is the estimate for the intercept? What is the estimate for gender? Use the [coef] function.
```{r}
coef(mod)
```
The estimate for the intercept is 3.5 and the estimate for gender is 4.3.

# Question 2:       
The second column of coef are standard errors. These can be calculated by taking the sqrt of the diag of the vcov of the summary of mod. Calculate the standard errors.
```{r}
sqrt(diag(vcov(summary(mod))))
```
The standard errors for intercept is 1.098701 and the standard error for genderM is 1.474061
<br><br>
The third column of coef are test statistics. These can be calculated by dividing the first column by the second column.
```{r}
mod <- lm(los ~ gender, dat=x)
mod.c <- coef(summary(mod))
mod.c[,1]/mod.c[,2]
```

# Question 3:      
Use the pt function to calculate the p value for gender. The first argument should be the test statistic for gender. The second argument is the degrees-of-freedom. Also, set the lower.tail argument to FALSE. Finally multiple this result by two.
```{r}
ttest <- (mod.c[,1]/mod.c[,2])
pvalue <- pt(ttest, df =7, lower.tail= FALSE)
print(2*pvalue)
```
<br><br>
Predicted Values  
The estimates can be used to create predicted values.
```{r}
3.5+(x$gender=='M')*4.3
```

# Question 1:      
It is even easier to see the predicted values by passing the model mod to the predict or fitted functions. Try it out.   
[predict]
```{r}
predict(mod)
```
[fitted]
```{r}
fitted(mod)
```
Yes. These two functions are easier to see the predicted values.

# Question 2:      
predict can also use a new data set. Pass newdat as the second argument to predict.
```{r}
newdat <- data.frame(gender=c('F','M','F'))
predict(mod, newdat)
```

# Question 1:      
Use one of the methods to generate predicted values. Subtract the predicted value from the x$los column.
```{r}
prevalue <- predict(mod)
x$los - prevalue
```

# Question 2:      
Try passing mod to the residuals function
```{r}
residuals(mod)
```

# Question 3:      
Square the residuals, and then sum these values. Compare this to the result of passing mod to the deviance function.

```{r}
rvalue <- residuals(mod)
sum((rvalue)^2)
deviance(mod)
sum((rvalue)^2) == deviance(mod)
```
As we can see from the result, the values from squaring the residuals and sum the values are exactly same as directly using deviance function. We can judge either by numerically the same (33.8) or if we set the two functions equal to each other and we get TRUE as the result.
<br><br>
```{r}
df.residual(mod)
```

# Question 1:      
Calculate standard error by dividing the deviance by the degrees-of-freedom, and then taking the square root. Verify that this matches the output labeled "Residual standard error" from summary(mod).
```{r}
sqrt(deviance(mod) / df.residual(mod))
summary(mod)
```
As we can see that the standard error we calculated is 2.197401 (can be round up to 2.197) and in the summary the residual standard error is 2.197. Thus, these two values are the same.
<br><br>
```{r}
predict(mod, se.fit=TRUE)$residual.scale
```
And the number also matches the output above.

# Question 1:      
Create a subset of x by taking all records where gender is 'M' and assigning it to the variable men. Do the same for the variable women.
```{r}
men <- subset(x, gender == "M", select = los)
women <- subset(x, gender == 'F', select = los)
```

# Question 1:  
By default a two-sampled t-test assumes that the two groups have unequal variances. You can calculate variance with the var function. Calculate variance for los for the men and women data sets.  
```{r}
var(men)
var(women)
```
The variance for los function for men is 5.2 and the variance for los function for women is approximately 4.333

# Question 1:  
Call the t.test function, where the first argument is los for women and the second argument is los for men. Call it a second time by adding the argument var.equal and setting it to TRUE. Does either produce output that matches the p value for gender from the model summary?
```{r}
t.test(women, men)
t.test(women, men, var.equal = TRUE)
summary(mod)
```

We can see that from the first call, the p-value is 0.2205 and the second  call is 0.224 where the second call p-value matches the p-value for gender in the summary (0.224) 


